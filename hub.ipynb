{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-A-124/testcolabnotebook/blob/main/hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIzICjaph_Wy"
      },
      "source": [
        "<a align=\"center\" href=\"https://ultralytics.com/hub\" target=\"_blank\">\n",
        "<img width=\"1024\", src=\"https://github.com/ultralytics/assets/raw/main/im/ultralytics-hub.png\"></a>\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "[‰∏≠Êñá](https://docs.ultralytics.com/zh/hub/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/hub/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/hub/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/hub/) | [Deutsch](https://docs.ultralytics.com/de/hub/) | [Fran√ßais](https://docs.ultralytics.com/fr/hub/) | [Espa√±ol](https://docs.ultralytics.com/es/hub/) | [Portugu√™s](https://docs.ultralytics.com/pt/hub/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/hub/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/hub/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/hub/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/hub/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/hub/actions/workflows/ci.yml/badge.svg\" alt=\"CI CPU\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/hub/blob/main/hub.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "\n",
        "Welcome to the [Ultralytics](https://ultralytics.com/) HUB notebook!\n",
        "\n",
        "This notebook allows you to train Ultralytics [YOLO](https://github.com/ultralytics/ultralytics) üöÄ models using [HUB](https://hub.ultralytics.com/). Please browse the HUB <a href=\"https://docs.ultralytics.com/hub/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/hub/issues/new/choose\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRQ2ow94MiOv"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyDnXd-n4c7Y",
        "outputId": "041a4329-4bfd-4c50-f610-0138d6b7eb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.150 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.6/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "from ultralytics import YOLO, checks, hub\n",
        "\n",
        "checks()  # Verify system setup for Ultralytics training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ9BwaAqxAm4"
      },
      "source": [
        "# Start\n",
        "\n",
        "‚ö° Login with your API key, load your YOLO üöÄ model, and start training in 3 lines of code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSlZaJ9Iw_iZ",
        "outputId": "59e62b7d-9c56-41c1-ad9a-b42b99afc67b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['hub-sdk>=0.0.12'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 0.8s\n",
            "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mNew authentication successful ‚úÖ\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mView model at https://hub.ultralytics.com/models/mGouIIkISq0Kvg06v6DX üöÄ\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38.8M/38.8M [00:00<00:00, 171MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.150 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=None, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=https://storage.googleapis.com/ultralytics-hub.appspot.com/users/dEk45Aw6g8gQoPLpDMa2ejj78hn2/datasets/pUzn5H51kDKo0mQnBX7O/RipCurrents_Humans_Existing_Dataset.zip, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://storage.googleapis.com/ultralytics-hub.appspot.com/users/dEk45Aw6g8gQoPLpDMa2ejj78hn2/datasets/pUzn5H51kDKo0mQnBX7O/RipCurrents_Humans_Existing_Dataset.zip to 'RipCurrents_Humans_Existing_Dataset.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.03G/2.03G [01:20<00:00, 27.1MB/s]\n",
            "Unzipping RipCurrents_Humans_Existing_Dataset.zip to /content/datasets/RipCurrents_Humans_Existing_Dataset...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60284/60284 [00:21<00:00, 2861.52file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 21.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   1412566  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
            "YOLO11m summary: 231 layers, 20,054,550 parameters, 20,054,534 gradients, 68.2 GFLOPs\n",
            "\n",
            "Transferred 643/649 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 119MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1387.1¬±782.0 MB/s, size: 67.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/RipCurrents_Humans_Existing_Dataset/labels/train... 21247 images, 655 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21247/21247 [00:09<00:00, 2164.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1002_jpg.rf.0f50be96f563703d01416fe77e3e2c52.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1002_jpg.rf.acb1fd5714c754734db5cbe9580acf59.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1002_jpg.rf.ffc8b2a4c6fa17f95bbe3d3b77d7ea07.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1004_jpg.rf.5e0807cc99b3bafcd1243426a6db9765.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1004_jpg.rf.c5ce212fa1bf4dc67875ef675e4bcc91.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1029_jpg.rf.17690b5df821acd3bc90276c6111d4a8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1029_jpg.rf.4bde18926826240eb052ae166b9e5577.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1029_jpg.rf.9a34d3b2a38bf59944551c78c0009639.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-103_jpg.rf.46becddfa71dfa636681d07b32282d0d.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-103_jpg.rf.df2912aef7d09f26354477a1d282682e.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-103_jpg.rf.f5bafdfa46aa1e0a175213354a2c9b54.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1077_jpg.rf.98b7583eb8eb660ce9678e5079a0d595.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1077_jpg.rf.fbcbd87bdf4b81d9b2700799a7de7080.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-108_jpg.rf.a4822d4cbd96d028d37ae1983e520d73.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-109_jpg.rf.a10aac6940ec2cbb171624ded1d92a04.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-109_jpg.rf.ea71e1bfbc7f560717106f1ebeb40cb3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1119_jpg.rf.00478e78ba3cb8f53ef43bf363ec4590.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-114_jpg.rf.e6959f806899ab52941f532d61af6a15.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-122_jpg.rf.856f3150fefcc745fd487cfb2b7339bc.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-122_jpg.rf.de0b37c970e2c4c27d9f13a09406a014.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-125_jpg.rf.02b2f6715d2f28cf834dea7ec76c208e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-125_jpg.rf.784be7767e3105841c39d210501cfa21.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-125_jpg.rf.7e744f4a7608637675d17b4ff9e2a2f6.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-126_jpg.rf.a061e8d7d7dec5b6dc7ecdd928b7205c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-270_jpg.rf.1ed256164300501ac74a079f003d9347.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-270_jpg.rf.72b6817742e5184cd86586f5c4af770c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-342_jpg.rf.dff52c24ef19bd58b18a7b805cf969b7.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-69_jpg.rf.3a86fc586ddb4eb18acc70bef089585d.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-69_jpg.rf.f4359decf3051411df0167bc6f9bf453.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-69_jpg.rf.fd26e88d14a2923668f5be1368bdac5c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-75_jpg.rf.99d70e0674331e9e54c92ecde2a02a80.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-75_jpg.rf.c1d5ad592b44792d9b9ec2ddba31beea.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-75_jpg.rf.d185e990af415023b9d79aefb2afae0a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-863_jpg.rf.4fa8ede7fff898cc633ab7d8d07c4b4e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-863_jpg.rf.9679a789101575f93985cf50e7000e8c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-863_jpg.rf.d2e92bc958a0e40161eb09146224b950.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-882_jpg.rf.38e036a8dcedfcd9100100bd67a658ba.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-882_jpg.rf.92dfd1c8e8486cddf783544542d19a89.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-882_jpg.rf.d2659fc661284135be59d6815d5c0d2a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-891_jpg.rf.0a8c2dd32dfab0ec1633979ed4e09c0c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-891_jpg.rf.325cb40ec732575489ba077b53d29227.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-891_jpg.rf.9464cec3f3ffb407d93793d0df832226.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-915_jpg.rf.2393e5cc9ac29ec637560a54d7083f19.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-915_jpg.rf.9e097d7116a05b4301a5cdcf8c0cd241.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-915_jpg.rf.d69699ca2edd26e9da7ee9afb5995244.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-921_jpg.rf.2b80a891e62cabe79ef37751927a2839.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-921_jpg.rf.6184cce52c0a852f5a6c2e7ffc151fa8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-927_jpg.rf.250972b32d942768323e9709c6307acb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-927_jpg.rf.5d36f08ac397e4717f0fc87b1948b8bf.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-927_jpg.rf.c1bd559ae2b29642c64eafc3e7cbc21d.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-92_jpg.rf.3f548a352e8810bef7453877ed3cd9fe.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-92_jpg.rf.9e1cec72463da5708d7dee39d78df642.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-945_jpg.rf.429a28223bc371886ffb509529149c6e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-945_jpg.rf.9abd754c8b8ab3c931582c082d4edcd3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-965_jpg.rf.e1d52ab8927d9002a39b430399107168.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-965_jpg.rf.e200b3e6cbc3cad29c38859fe146efb8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-436_jpg.rf.0ca7409d7c90516ba7ffa7b2f291f679.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-436_jpg.rf.25c7980beb0e6f420cd3d809b236fd40.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-440_jpg.rf.3fc8985ece3d684b48e6b32c2796fb67.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-441_jpg.rf.99a6fbd032583ff65d6ed901cb2c96eb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-441_jpg.rf.d1d94ec75e123d67377cff21a4bd3b88.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-492_jpg.rf.131ae7ec5dbae8a841c57ff87a704acb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-520_jpg.rf.77635d531ca4583f4f705ff447f0d734.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-521_jpg.rf.75d204584522be69e2a82548870a2d29.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-521_jpg.rf.d4d13e561c7bc857dc1b16219c8ac73e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-525_jpg.rf.7c0b09464ae523f7fa6c4eb23732963a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-530_jpg.rf.73a7d395feeda36fa39b371ca02f243c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-530_jpg.rf.93bdb41b025493d871aaa44cc282d152.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-531_jpg.rf.a26963b243e72cacf09e035681bbe93f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-531_jpg.rf.ba27b8226e0f1e75c927e40ffb3b17d4.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-531_jpg.rf.f56d09fa38917c0e5d8d0d26c1b6fe75.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/RipCurrents_Humans_Existing_Dataset/labels/train.cache\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 33, len(boxes) = 101223. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.21G reserved, 0.21G allocated, 14.32G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "    20054550       68.19         1.671         94.18         551.1        (1, 3, 640, 640)                    list\n",
            "    20054550       136.4         2.324         43.57         129.4        (2, 3, 640, 640)                    list\n",
            "    20054550       272.8         3.446         50.93         123.8        (4, 3, 640, 640)                    list\n",
            "    20054550       545.5         5.614         87.74         173.5        (8, 3, 640, 640)                    list\n",
            "    20054550        1091         9.989         178.5         298.1       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 14 for CUDA:0 9.33G/14.74G (63%) ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1954.0¬±649.0 MB/s, size: 64.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/RipCurrents_Humans_Existing_Dataset/labels/train.cache... 21247 images, 655 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21247/21247 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1002_jpg.rf.0f50be96f563703d01416fe77e3e2c52.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1002_jpg.rf.acb1fd5714c754734db5cbe9580acf59.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1002_jpg.rf.ffc8b2a4c6fa17f95bbe3d3b77d7ea07.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1004_jpg.rf.5e0807cc99b3bafcd1243426a6db9765.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1004_jpg.rf.c5ce212fa1bf4dc67875ef675e4bcc91.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1029_jpg.rf.17690b5df821acd3bc90276c6111d4a8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1029_jpg.rf.4bde18926826240eb052ae166b9e5577.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1029_jpg.rf.9a34d3b2a38bf59944551c78c0009639.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-103_jpg.rf.46becddfa71dfa636681d07b32282d0d.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-103_jpg.rf.df2912aef7d09f26354477a1d282682e.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-103_jpg.rf.f5bafdfa46aa1e0a175213354a2c9b54.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1077_jpg.rf.98b7583eb8eb660ce9678e5079a0d595.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1077_jpg.rf.fbcbd87bdf4b81d9b2700799a7de7080.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-108_jpg.rf.a4822d4cbd96d028d37ae1983e520d73.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-109_jpg.rf.a10aac6940ec2cbb171624ded1d92a04.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-109_jpg.rf.ea71e1bfbc7f560717106f1ebeb40cb3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-1119_jpg.rf.00478e78ba3cb8f53ef43bf363ec4590.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-114_jpg.rf.e6959f806899ab52941f532d61af6a15.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-122_jpg.rf.856f3150fefcc745fd487cfb2b7339bc.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-122_jpg.rf.de0b37c970e2c4c27d9f13a09406a014.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-125_jpg.rf.02b2f6715d2f28cf834dea7ec76c208e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-125_jpg.rf.784be7767e3105841c39d210501cfa21.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-125_jpg.rf.7e744f4a7608637675d17b4ff9e2a2f6.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-126_jpg.rf.a061e8d7d7dec5b6dc7ecdd928b7205c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-270_jpg.rf.1ed256164300501ac74a079f003d9347.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-270_jpg.rf.72b6817742e5184cd86586f5c4af770c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-342_jpg.rf.dff52c24ef19bd58b18a7b805cf969b7.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-69_jpg.rf.3a86fc586ddb4eb18acc70bef089585d.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-69_jpg.rf.f4359decf3051411df0167bc6f9bf453.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-69_jpg.rf.fd26e88d14a2923668f5be1368bdac5c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-75_jpg.rf.99d70e0674331e9e54c92ecde2a02a80.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-75_jpg.rf.c1d5ad592b44792d9b9ec2ddba31beea.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-75_jpg.rf.d185e990af415023b9d79aefb2afae0a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-863_jpg.rf.4fa8ede7fff898cc633ab7d8d07c4b4e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-863_jpg.rf.9679a789101575f93985cf50e7000e8c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-863_jpg.rf.d2e92bc958a0e40161eb09146224b950.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-882_jpg.rf.38e036a8dcedfcd9100100bd67a658ba.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-882_jpg.rf.92dfd1c8e8486cddf783544542d19a89.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-882_jpg.rf.d2659fc661284135be59d6815d5c0d2a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-891_jpg.rf.0a8c2dd32dfab0ec1633979ed4e09c0c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-891_jpg.rf.325cb40ec732575489ba077b53d29227.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-891_jpg.rf.9464cec3f3ffb407d93793d0df832226.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-915_jpg.rf.2393e5cc9ac29ec637560a54d7083f19.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-915_jpg.rf.9e097d7116a05b4301a5cdcf8c0cd241.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-915_jpg.rf.d69699ca2edd26e9da7ee9afb5995244.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-921_jpg.rf.2b80a891e62cabe79ef37751927a2839.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-921_jpg.rf.6184cce52c0a852f5a6c2e7ffc151fa8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-927_jpg.rf.250972b32d942768323e9709c6307acb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-927_jpg.rf.5d36f08ac397e4717f0fc87b1948b8bf.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-927_jpg.rf.c1bd559ae2b29642c64eafc3e7cbc21d.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-92_jpg.rf.3f548a352e8810bef7453877ed3cd9fe.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-92_jpg.rf.9e1cec72463da5708d7dee39d78df642.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-945_jpg.rf.429a28223bc371886ffb509529149c6e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-945_jpg.rf.9abd754c8b8ab3c931582c082d4edcd3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-965_jpg.rf.e1d52ab8927d9002a39b430399107168.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_141426_mp4-965_jpg.rf.e200b3e6cbc3cad29c38859fe146efb8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-436_jpg.rf.0ca7409d7c90516ba7ffa7b2f291f679.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-436_jpg.rf.25c7980beb0e6f420cd3d809b236fd40.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-440_jpg.rf.3fc8985ece3d684b48e6b32c2796fb67.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-441_jpg.rf.99a6fbd032583ff65d6ed901cb2c96eb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-441_jpg.rf.d1d94ec75e123d67377cff21a4bd3b88.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-492_jpg.rf.131ae7ec5dbae8a841c57ff87a704acb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-520_jpg.rf.77635d531ca4583f4f705ff447f0d734.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-521_jpg.rf.75d204584522be69e2a82548870a2d29.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-521_jpg.rf.d4d13e561c7bc857dc1b16219c8ac73e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-525_jpg.rf.7c0b09464ae523f7fa6c4eb23732963a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-530_jpg.rf.73a7d395feeda36fa39b371ca02f243c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-530_jpg.rf.93bdb41b025493d871aaa44cc282d152.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-531_jpg.rf.a26963b243e72cacf09e035681bbe93f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-531_jpg.rf.ba27b8226e0f1e75c927e40ffb3b17d4.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/train/20220904_143054_mp4-531_jpg.rf.f56d09fa38917c0e5d8d0d26c1b6fe75.jpg: 1 duplicate labels removed\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 33, len(boxes) = 101223. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1454.8¬±703.4 MB/s, size: 77.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/RipCurrents_Humans_Existing_Dataset/labels/val... 5925 images, 43 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5925/5925 [00:03<00:00, 1649.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-1077_jpg.rf.86b892732a02670983ed3dbbd8f0d5d8.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-108_jpg.rf.70ffacd23b9e47a3edee57dd6a5785a9.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-108_jpg.rf.8ecd1b68a0849ec5088165abdbc59590.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-109_jpg.rf.0464bd466e22b63c9ad08bf1b4782ab1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-343_jpg.rf.51f02a20531e2313e8c1a4412a7189e2.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-921_jpg.rf.7dbab53c5d5f7b120f9253731f4d9b92.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-92_jpg.rf.a400728c53a6f34234b135b33cdb7a01.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_141426_mp4-965_jpg.rf.301b39b03bba1b14670ae72ed37c1e8a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_143054_mp4-436_jpg.rf.becbad1611193f3a9c03525a57ad3fb7.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_143054_mp4-437_jpg.rf.849ea69104cbc54b00e61b18f349e4e1.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_143054_mp4-491_jpg.rf.8b436be986586d284a657f58fcbe2401.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_143054_mp4-521_jpg.rf.31092452a6deb71276b611a2ca0573a1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_143054_mp4-530_jpg.rf.e0515312a0af99ad80854e2fc980113f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/RipCurrents_Humans_Existing_Dataset/images/val/20220904_143054_mp4-802_jpg.rf.4e38c9837ad74c416486d5cc1970f4f6.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/RipCurrents_Humans_Existing_Dataset/labels/val.cache\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 7, len(boxes) = 30007. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.000546875), 112 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100       7.3G      1.922      1.778      1.708         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1518/1518 [13:36<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 160/212 [01:16<00:28,  1.84it/s]"
          ]
        }
      ],
      "source": [
        "hub.login('dcc57beff01aa452aebb6a8a0dd0b85c3e2b53ad24')\n",
        "\n",
        "model = YOLO('https://hub.ultralytics.com/models/mGouIIkISq0Kvg06v6DX')\n",
        "results = model.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Ultralytics HUB",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}